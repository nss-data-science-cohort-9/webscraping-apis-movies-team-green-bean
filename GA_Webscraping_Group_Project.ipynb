{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ca5b105-492d-4884-807a-269e364048e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763a15e0-f35e-44f7-b7cc-8a332b611e49",
   "metadata": {},
   "source": [
    "# An Analysis of Movie Performance\n",
    "\n",
    "In this part, you’ll gather data about popular movies and award winners. The goal is to build a dataset that you’ll later use to analyze what makes a movie successful and how awards and box office performance relate to one another.\n",
    "\n",
    "### Part 1: Data Gathering\n",
    "1. Scrape Best Picture Data.  \n",
    "    * Scrape the [Best Picture wikipedia page](https://en.wikipedia.org/wiki/Academy_Award_for_Best_Picture).  \n",
    "    * Extract for each year:  \n",
    "        * Year  \n",
    "        * Film Title  \n",
    "        * Winner (Yes/No)  \n",
    "    * Data cleaning tips:  \n",
    "        * Ensure that year and film title columns are clean and consistent (no footnotes, parentheses, etc.).\n",
    "        * Save the results as best_picture.csv.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bd7806f-4be7-47d2-8885-5fb5440163f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in website for webscraping\n",
    "URL = 'https://en.wikipedia.org/wiki/Academy_Award_for_Best_Picture'\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"MyPythonScraper\"\n",
    "}\n",
    "\n",
    "response = requests.get(URL, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "799cf7af-8701-4069-9211-6ab170cdc3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for connection\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a644ac7f-8fe8-436b-8d22-4fe45a064198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 'soup' object from fake jobs website scrape\n",
    "movies_soup = BeautifulSoup(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5623850-e04f-421a-94e5-c73de40acbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html class=\"client-nojs vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-page-tools-pinned-disabled vector-feature-toc-pinned-clientpref-1 vector-feature-main-menu-pinned-disabled vector-feature-limited-width-clientpref-1 vector-feature-limited-width-content-enabled vector-feature-custom-font-size-clientpref-1 vector-feature-appearance-pinned-clientpref-1 vector-feature-night-mode-enabled skin-theme-clientpref-day vect\n"
     ]
    }
   ],
   "source": [
    "# display readable webscrape \n",
    "print(movies_soup.prettify()[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d156a533-5d69-48d8-998c-30b720b73a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# locate number of tables in url\n",
    "len(movies_soup.findAll('table'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a61dbc7-3cd1-4d4a-af59-4fee4402b0d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f25c910d-62f6-45d3-bb30-b78888882c57",
   "metadata": {},
   "source": [
    "2. Gather Movie Data via TMDB API  \n",
    "    a. Set up the API    \n",
    "    * Create a free [TMDB account](https://developer.themoviedb.org/docs/getting-started)  \n",
    "    * Generate an API key are review their documentation, especially:  \n",
    "        * /discover/movie  \n",
    "        * /movie/{movie_id}  \n",
    "        * /search/movie  \n",
    "    b. Collect top movies (2015-2024)  \n",
    "    For each year from 2015 to 2024:  \n",
    "        * Query TMDB for the top 100 movies (by vote count).  \n",
    "        * For each movie, gather:  \n",
    "            * Title  \n",
    "            * Release Year  \n",
    "            * Genre(s)  \n",
    "            * Vote Average  \n",
    "            * Vote Count  \n",
    "            * Budget  \n",
    "            * Revenue  \n",
    "            * TMDB ID  \n",
    "        * Store all results in a single DataFrame and export to movies_2015_2024.csv.\n",
    "        * Hint: TMDB rate limits are generous for free accounts, but you should pause between requests (eg. time.sleep(0.25)). \n",
    "        * Some Oscar films may not appear in the top 100 by vote count. For any missing, use the /search/movie endpoint to add it.  \n",
    "\n",
    "**Optional Extension: Actors and Actresses** \n",
    "\n",
    "1. Scrape Wikipedia for Best Actor and Best Actress Data\n",
    "    * Scrape the following Wikipedia pages:  \n",
    "        * [Best Actor](https://en.wikipedia.org/wiki/Academy_Award_for_Best_Actor)\n",
    "        * [Best Actress](https://en.wikipedia.org/wiki/Academy_Award_for_Best_Actress)\n",
    "    * Each apge contains tables of winners and nominees by year.\n",
    "    * Extract the following columns:  \n",
    "        * Year\n",
    "        * Actor/Actress Name\n",
    "        * Film Title\n",
    "        * Winner (Yes/No)\n",
    "    * Data cleaning tips:  \n",
    "        * Remove footnote markers from names and movie titles.\n",
    "        * Ensure that you save just the release year (eg. 2009 instead of 2009 (82nd))\n",
    "        * Store the cleaned data as two csv files:  \n",
    "            * best_actor.csv\n",
    "            * best_actress.csv  \n",
    "\n",
    "2. Collect Actor and Actress Filmographies  \n",
    "    Using the data from your actor and actresses CSVs:  \n",
    "    * Search TMDB for each recent performer (using /search/person). Note: you can start with 2015-2024 initially, but, if time allows, you can go back even further.\n",
    "    * For each person, retrieve their movie credits using /person/{person_id}/movie_credits.  \n",
    "    * Extract relevant fields for each movie, such as:  \n",
    "        * Actor/Actress Name  \n",
    "        * Movie Title  \n",
    "        * Character Name (optional)  \n",
    "        * Release Year  \n",
    "        * Movie ID\n",
    "    * Combine all filmographies into one file, actor_filmography.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af785cd0-0d67-4848-8743-f234b353cd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sivarajas code to solve all of part one\n",
    "\n",
    "movies = []\n",
    "for row in table.find_all('tr')[1:]:  \n",
    "        cols = row.find_all('td')\n",
    "        if len(cols) > 1:  \n",
    "            year = cols[0].text.strip()\n",
    "            title = cols[1].text.strip()\n",
    "            winner = \"Yes\" \n",
    "                        \n",
    "            movies.append({\n",
    "                'Year': year,\n",
    "                'Film Title': title,\n",
    "                'Winner': winner\n",
    "            })\n",
    "df = pd.DataFrame(movies)\n",
    "df.to_csv('best_picture_winners.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
